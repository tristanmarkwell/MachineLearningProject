---
title: "Predicting Activity"
author: "Tristan Markwell"
date: "Saturday, September 20, 2014"
output: html_document
---
#Predicting Activity
##Tristan Markwell

##Motivation
The objective is to detect a person's state of activity (sitting, standing, sitting down, standing up, or walking) from wearable device data.  The data was downloaded on 
```{r}
set.seed(1234)
library(caret)
library(gbm)
if (!file.exists('data')) dir.create('data')
##download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv',
##              '.\\data\\training.csv')
##download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv',
##              '.\\data\\testing.csv')
downloadDate <- date()
downloadDate
```

##Data Processing
There were two main problems in the data.  First, many of the columns will filled with NA values.  Second, the numeric columns are read in as factors by the read.csv command.  Majority-NA columns were removed, and then the factors were forced to numeric:

```{r}
trainingData <- read.csv('.\\data\\training.csv')
testing <- read.csv('.\\data\\testing.csv')
partition <- createDataPartition(y=trainingData$classe, p=.7, list=FALSE)
training <- trainingData[partition, ]
finalTraining <- training[,colMeans(is.na(training))<.5 & colMeans(is.na(testing))<.5]
##most of the factors are actually numbers - force numeric
finalTraining$X <- NULL
finalTraining$user_name <- NULL ## bring back for prediction
finalTraining$cvtd_timestamp <- NULL
finalTraining$classe <- NULL
finalTraining <- as.data.frame(lapply(finalTraining,as.numeric))
finalTraining$user_name <- training$user_name
finalTraining$classe <- training$classe
dummies <- dummyVars(classe ~ ., data=finalTraining)
finalTraining <- data.frame(predict(dummies, newdata = finalTraining))
finalTraining$classe <- training$classe
```

##Training

The model fit was a mulitnomial neural network, with folded cross-validation used to prevent overfitting.
```{r, results='hide'}
fitControl <- trainControl(## 5-fold CV
  method = "repeatedcv",
  number = 5,
  ## repeated five times
  repeats = 5)
##modFit <- gbm(classe~., data=finalTraining)
modFit <- train(classe~., method="multinom", trControl=fitControl, data=finalTraining)
```

##Accuracy Estimation
The data held back should give an accurate estimate of the error on fresh data.  Judging by accuracy:
```{r}
## processing validation set just like training
validation <- trainingData[-partition, ]
finalValidation <- validation[,colMeans(is.na(training))<.5 & colMeans(is.na(testing))<.5]
##most of the factors are actually numbers - force numeric
finalValidation$X <- NULL
finalValidation$user_name <- NULL ## bring back for prediction
finalValidation$cvtd_timestamp <- NULL
finalValidation$classe <- NULL
finalValidation <- as.data.frame(lapply(finalValidation,as.numeric))
finalValidation$user_name <- validation$user_name
finalValidation$classe <- validation$classe
finalValidation <- data.frame(predict(dummies, newdata = finalValidation))
validationPreds <- data.frame(predict(modFit, newdata=finalValidation))
mean(validation$classe==validationPreds[,1])
```

##Prediction
The same procedure can be applied to the test data to get predictions:
```{r}
## now for the test data
finalTesting <- testing[colMeans(is.na(training))<.5 & colMeans(is.na(testing))<.5]
##most of the factors are actually numbers - force numeric
finalTesting$X <- NULL
finalTesting$problem_id <- NULL
finalTesting$user_name <- NULL ## bring back for prediction
finalTesting$cvtd_timestamp <- NULL
finalTesting$classe <- NULL
finalTesting <- as.data.frame(lapply(finalTesting,as.numeric))
finalTesting$user_name <- testing$user_name
finalTesting$classe <- rep("A",20)
finalTesting <- data.frame(predict(dummies, newdata = finalTesting))
testingPreds <- predict(modFit, newdata=finalTesting)
testingPreds
```